[{"id":1849,"annotations":[{"id":589,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"CWRQst3T8V","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["Does not have any dependent clauses"]},"id":"COtsNfKqus","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:21:04.717639Z","updated_at":"2023-07-16T19:21:04.717639Z","draft_created_at":"2023-07-16T19:20:44.133493Z","lead_time":96.396,"prediction":{},"result_count":0,"unique_id":"c7f674ac-ea5f-486c-8b60-9900fc92c31e","last_action":null,"task":1849,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"A number of highly-threaded, many-core Antarctica architectures hide memory-access latency by low-overhead context switching among a large number of threads."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:21:04.843340Z","inner_id":1,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1850,"annotations":[{"id":590,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"KljbNXEyQ-","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:21:28.843877Z","updated_at":"2023-07-16T19:21:34.291588Z","draft_created_at":null,"lead_time":26.018,"prediction":{},"result_count":0,"unique_id":"90d31372-61ee-4f92-a2fb-6f84378dd623","last_action":null,"task":1850,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"If the number of threads were infinite, theoretically, these machines could provide the performance predicted by the PRAM analysis of these programs."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:21:34.401705Z","inner_id":2,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1851,"annotations":[{"id":591,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"AQuQzNsX86","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:21:53.194014Z","updated_at":"2023-07-16T19:21:53.194014Z","draft_created_at":null,"lead_time":14.482,"prediction":{},"result_count":0,"unique_id":"301f2913-9b02-47d6-8de8-49157388abec","last_action":null,"task":1851,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this paper, we introduce the Threaded Many-core Memory (TMM) model which is meant to capture the important characteristics of these highly-threaded, many-core machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:21:53.304576Z","inner_id":3,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1852,"annotations":[{"id":592,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Long Intro Phrase"]]},"id":"AGOelTHQKx","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["The introductory clause is longer than 7 words"]},"id":"KkGvA1KIJE","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:24:18.541164Z","updated_at":"2023-07-16T19:24:18.541164Z","draft_created_at":"2023-07-16T19:22:40.936816Z","lead_time":144.747,"prediction":{},"result_count":0,"unique_id":"42556e4c-ef32-4679-a8c5-2b45a8b86c9a","last_action":null,"task":1852,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Since we model some important machine parameters of these machines, we expect analysis under this model to provide a more fine-grained and accurate performance prediction than the PRAM analysis."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:24:18.652364Z","inner_id":4,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1853,"annotations":[{"id":593,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"6yI_jRrlT2","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["2 independent clauses separated by a comma"]},"id":"yBksJoyvmK","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:25:09.846043Z","updated_at":"2023-07-16T19:25:09.846043Z","draft_created_at":"2023-07-16T19:24:55.181832Z","lead_time":50.662,"prediction":{},"result_count":0,"unique_id":"215ad0f5-b267-429c-a2b4-6a2525bb9be3","last_action":null,"task":1853,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We find that even when two algorithms have the same PRAM performance, our model predicts different performance for some settings of machine parameters."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:25:09.960824Z","inner_id":5,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1854,"annotations":[{"id":594,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"_pSwySox7-","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["Does not have any dependent clauses, only prepositional phrases"]},"id":"JdzJXsvOqN","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:25:40.258743Z","updated_at":"2023-07-16T19:25:40.258743Z","draft_created_at":"2023-07-16T19:25:33.579312Z","lead_time":29.707,"prediction":{},"result_count":0,"unique_id":"29a1f346-3ecf-4225-b079-2da86464d28a","last_action":null,"task":1854,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"For example, for dense graphs, the dynamic programming algorithm and Johnson's algorithm have the same performance in the PRAM model."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:25:40.368753Z","inner_id":6,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1855,"annotations":[{"id":595,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"0g1WsbAakZ","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:27:30.752887Z","updated_at":"2023-07-16T19:27:30.752887Z","draft_created_at":"2023-07-16T19:25:59.159735Z","lead_time":109.556,"prediction":{},"result_count":0,"unique_id":"bcf21b92-c925-4e32-9330-69a9f7bed63b","last_action":null,"task":1855,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, our model predicts different performance for large enough memory-access latency and validates the intuition that the dynamic programming algorithm performs better on these machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:27:30.863085Z","inner_id":7,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1856,"annotations":[{"id":596,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"X8Jw7PTbf7","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["\"Using empirical..\" is a verb phrase. The sentence does not have any dependent clauses"]},"id":"N7eh--A6_g","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:31:01.686066Z","updated_at":"2023-07-16T19:31:01.686066Z","draft_created_at":"2023-07-16T19:27:49.476506Z","lead_time":209.933,"prediction":{},"result_count":0,"unique_id":"cae679b4-760f-48c9-88e9-52ba91ac6bf5","last_action":null,"task":1856,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We validate several predictions made by our model using empirical measurements on an instantiation of a highly-threaded, many-core machine, namely the NVIDIA GTX 480."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:31:01.811946Z","inner_id":8,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1857,"annotations":[{"id":597,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"fBQoMwaMz1","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["2 independent clauses separated by a semicolon are classified as structured"]},"id":"yxkvAbZOXX","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:31:46.251453Z","updated_at":"2023-07-16T19:31:46.251453Z","draft_created_at":"2023-07-16T19:31:32.198180Z","lead_time":43.797,"prediction":{},"result_count":0,"unique_id":"16c6b838-4365-44ab-8689-ec5b469c365d","last_action":null,"task":1857,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Highly-threaded, many-core devices such as GPUs have gained popularity in the last decade; both NVIDIA and AMD manufacture general purpose GPUs that fall in this category."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:31:46.351793Z","inner_id":9,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1858,"annotations":[{"id":598,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Long Subject"]]},"id":"24kufJOAbd","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["Includes a long subject and an abstract subject as the simple subject (nominalization of distinction). "]},"id":"ehdvAhe0qQ","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:33:31.813173Z","updated_at":"2023-07-16T19:33:31.813173Z","draft_created_at":"2023-07-16T19:32:12.138066Z","lead_time":104.868,"prediction":{},"result_count":0,"unique_id":"65ec59c1-3ba5-40fb-8442-1b80127b3812","last_action":null,"task":1858,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The important distinction between these machines and traditional multi-core machines is that these devices provide a large number of low-overhead hardware threads with low-overhead context switching between them; this fast context-switch mechanism is used to hide the memory access latency of transferring data from slow large (and often global) memory to fast, small (and typically local) memory."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:33:31.923798Z","inner_id":10,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1859,"annotations":[{"id":599,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"Nkumr7ZbIz","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["Does not have any dependent clauses"]},"id":"c3eZP6tv9p","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:33:48.911709Z","updated_at":"2023-07-16T19:33:48.911709Z","draft_created_at":null,"lead_time":16.459,"prediction":{},"result_count":0,"unique_id":"ab9aa2bf-edb9-4471-9252-18fcadee2f64","last_action":null,"task":1859,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Researchers have designed algorithms to solve many interesting problems for these devices, such as GPU sorting or hashing [1-4], linear algebra [5-7], dynamic programming [8,9], graph algorithms [10-13], and many other classic algorithms [14,15]."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:33:49.038296Z","inner_id":11,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1860,"annotations":[{"id":600,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Long Intro Phrase"]]},"id":"Te-uhvCRVH","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["contains a long intro adverbial dependent clause (while...) and intro prepositional phrase (in addition...)"]},"id":"ApYbAlIzNW","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:35:55.402638Z","updated_at":"2023-07-16T19:35:55.402638Z","draft_created_at":"2023-07-16T19:34:11.948140Z","lead_time":125.482,"prediction":{},"result_count":0,"unique_id":"34bb0928-cc14-4387-a21c-f34f8cb4f1a5","last_action":null,"task":1860,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"While there is a lot of folk wisdom on how to design good algorithms for these highly-threaded machines, in addition to a significant body of work on performance analysis [16-20], there are no systematic theoretical models to analyze the performance of programs on these machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:35:55.513776Z","inner_id":12,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1861,"annotations":[{"id":601,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"JIy46z_gPz","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["Does not have any dependent clauses"]},"id":"yoVPSDGeyO","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:39:13.220991Z","updated_at":"2023-07-16T19:39:13.220991Z","draft_created_at":null,"lead_time":93.618,"prediction":{},"result_count":0,"unique_id":"c8ead5d9-6496-4cc0-85d4-20bc2c1097f5","last_action":null,"task":1861,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We are interested in analyzing and characterizing performance of algorithms on these highly-threaded, many-core machines in a more abstract, algorithmic, and systematic manner."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:39:13.347594Z","inner_id":13,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1862,"annotations":[{"id":602,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"2GzvFcqCEF","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["The semicolon separates an independent clause from an dependent clause + independent clause. But the dependent clause is acting to connect the 2 indepenedent clauses, so in this case we will consider it structured."]},"id":"SYj1y7enTR","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:41:59.640872Z","updated_at":"2023-07-16T19:41:59.640872Z","draft_created_at":"2023-07-16T19:39:50.499266Z","lead_time":165.412,"prediction":{},"result_count":0,"unique_id":"9e3a3013-ce11-4739-bbaf-344574f9860a","last_action":null,"task":1862,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Theoretical analysis relies upon models that represent underlying assumptions; if a model does not capture the important aspects of target machines and programs, then the analysis is not predictive of real performance."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:41:59.756128Z","inner_id":14,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1863,"annotations":[{"id":603,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Long Subject"]]},"id":"kswiJDckzX","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:42:57.912011Z","updated_at":"2023-07-16T19:42:57.912011Z","draft_created_at":"2023-07-16T19:42:27.669277Z","lead_time":49.638,"prediction":{},"result_count":0,"unique_id":"7fc33abf-33b4-4e87-b1df-be6530659e8b","last_action":null,"task":1863,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The most fundamental model that is used to analyze sequential algorithms is the Random Access Machine (RAM) model [21], which we teach undergraduates in their first algorithms class."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:42:58.022722Z","inner_id":15,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1864,"annotations":[{"id":604,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Long Intro Phrase"]]},"id":"5zNeeOXXEy","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:43:22.690642Z","updated_at":"2023-07-16T19:43:22.690642Z","draft_created_at":null,"lead_time":24.152,"prediction":{},"result_count":0,"unique_id":"84808a47-5bc3-4e28-bc83-28fc8c44b31e","last_action":null,"task":1864,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"While this model is a good predictor of performance on computationally intensive programs, it does not properly capture the important characteristics of the memory hierarchy of modern machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:43:22.800455Z","inner_id":16,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1865,"annotations":[{"id":605,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"fhDATxNBvT","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:43:35.571605Z","updated_at":"2023-07-16T19:43:35.571605Z","draft_created_at":null,"lead_time":12.259,"prediction":{},"result_count":0,"unique_id":"760f07b0-47af-46e2-ac66-11e912d96bc4","last_action":null,"task":1865,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Aggarwal and Vitter proposed the Disk Access Machine (DAM) model [22] which counts the number of memory transfers from slow to fast memory instead of simply counting the number of memory accesses by the program."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:43:35.683020Z","inner_id":17,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1866,"annotations":[{"id":606,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"yKpeQmTvWc","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["the phrase \"exploiting spatial and temporal locality on these machines can lead to better performance.\" does not exhibit any shapelessness, its well coordinated in the sentence."]},"id":"L1pibXHnkz","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T19:58:58.032748Z","updated_at":"2023-07-16T19:58:58.032748Z","draft_created_at":"2023-07-16T19:57:10.381539Z","lead_time":921.485,"prediction":{},"result_count":0,"unique_id":"5650ad30-bc72-46c0-87a1-c5b3e0e475f2","last_action":null,"task":1866,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, it better captures the fact that modern machines have memory hierarchies and exploiting spatial and temporal locality on these machines can lead to better performance."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T19:58:58.142695Z","inner_id":18,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1867,"annotations":[{"id":607,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"_GNQ5F8otH","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["contains exactly 20 words and a dependent clause, so it is a structured sentence."]},"id":"IjjEquKW3M","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:01:28.760131Z","updated_at":"2023-07-16T20:01:28.760131Z","draft_created_at":"2023-07-16T19:59:25.947607Z","lead_time":149.75,"prediction":{},"result_count":0,"unique_id":"368eef55-5a1f-4071-8952-0d0f4a25e7a7","last_action":null,"task":1867,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"There are also a number of other models that consider the memory access costs of sequential algorithms in different ways [23-29]."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:01:28.870472Z","inner_id":19,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1868,"annotations":[{"id":608,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"CYjXUyad2u","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["2 independent clauses separated by a comma and coordinating conjunction (and)"]},"id":"QMGyZ4MQex","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:02:18.125803Z","updated_at":"2023-07-16T20:02:18.125803Z","draft_created_at":"2023-07-16T20:01:58.238645Z","lead_time":48.677,"prediction":{},"result_count":0,"unique_id":"c89d7b38-89d1-4112-ad32-aece849a8d47","last_action":null,"task":1868,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"For parallel computing, the analogue for the RAM model is the Parallel Random Access Machine (PRAM) model [30], and there is a large body of work describing and analyzing algorithms in the PRAM model [31,32]."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:02:18.236294Z","inner_id":20,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1869,"annotations":[{"id":609,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"SBIWbeoZeP","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["long simple sentence with no dependent clauses"]},"id":"rXuGBwGE6v","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:03:05.439099Z","updated_at":"2023-07-16T20:03:05.439099Z","draft_created_at":"2023-07-16T20:02:33.749124Z","lead_time":46.573,"prediction":{},"result_count":0,"unique_id":"5290732c-b1b6-492d-9222-5bcc1d9e7cfa","last_action":null,"task":1869,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In the PRAM model, the algorithm's complexity is analyzed in terms of its work-the time taken by the algorithm on 1 processor, and span (also called depth and critical-path length)-the time taken by the algorithm on an infinite number of processors."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:03:05.549102Z","inner_id":21,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1870,"annotations":[{"id":610,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"IVJWjqIe72","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:03:20.183026Z","updated_at":"2023-07-16T20:03:20.183026Z","draft_created_at":"2023-07-16T20:03:17.698314Z","lead_time":14.013,"prediction":{},"result_count":0,"unique_id":"1fdec887-b361-4f8c-b6af-a46aa4ecab05","last_action":null,"task":1870,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The PRAM model also ignores the vagaries of the memory hierarchy and assumes that each memory access by the algorithm takes unit time."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:03:20.293309Z","inner_id":22,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1871,"annotations":[{"id":611,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"LW9hVWrYGj","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:03:34.403885Z","updated_at":"2023-07-16T20:03:34.403885Z","draft_created_at":null,"lead_time":13.554,"prediction":{},"result_count":0,"unique_id":"0cf88174-997a-4c89-8c20-91de26c70fb4","last_action":null,"task":1871,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, researchers have designed various models that capture memory hierarchies for various types of machines such as distributed memory machines [33-35], shared memory machines and multi-cores [36-40], or the combination of the two [41,42]."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:03:34.514635Z","inner_id":23,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1872,"annotations":[{"id":612,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"-j_tt-tjA2","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["Does not have any dependent clauses"]},"id":"J5UKvmcQ8U","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:07:20.606133Z","updated_at":"2023-07-16T20:07:20.606133Z","draft_created_at":"2023-07-16T20:07:02.489146Z","lead_time":225.301,"prediction":{},"result_count":0,"unique_id":"8723126f-12a7-4772-8c80-7f4dfe483aad","last_action":null,"task":1872,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"All of these models capture particular capabilities and properties of the respective target machines, namely shared memory machines or distributed memory machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:07:20.716509Z","inner_id":24,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1873,"annotations":[{"id":613,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Long Intro Phrase"]]},"id":"giWMusX1zs","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:09:27.898110Z","updated_at":"2023-07-16T20:09:27.898110Z","draft_created_at":"2023-07-16T20:07:49.266671Z","lead_time":126.307,"prediction":{},"result_count":0,"unique_id":"4bdf6949-6709-49ca-b2de-84d61f7470d8","last_action":null,"task":1873,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"While superficially highly-threaded, many-core machines such as GPUs are shared memory machines, their characteristics are very different from traditional multi-core or multiprocessor shared memory machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:09:28.009128Z","inner_id":25,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1874,"annotations":[{"id":614,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless","Sprawling Ending"],["Shapeless"]]},"id":"J2f0VH_tAp","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["There are 3 dependent clauses tacked after each other in this sentence (that only..), (and this thread),(when there is...)"]},"id":"AbwUABYgz4","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:45:35.041265Z","updated_at":"2023-07-16T20:45:35.041265Z","draft_created_at":"2023-07-16T20:12:57.718458Z","lead_time":2166.037,"prediction":{},"result_count":0,"unique_id":"725a73e5-b3a2-47e6-ab12-a5c04c439a73","last_action":null,"task":1874,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"On multi-core machines, context switch cost is high, and most models nominally assume that only one (or a small constant number of) thread(s) are running on each machine and this thread blocks when there is a memory access."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:45:35.166043Z","inner_id":26,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1875,"annotations":[{"id":615,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"KHAJpLUvV-","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:45:49.254219Z","updated_at":"2023-07-16T20:45:49.254219Z","draft_created_at":null,"lead_time":13.53,"prediction":{},"result_count":0,"unique_id":"2950a67b-2402-41ff-9cf3-41feddce2efa","last_action":null,"task":1875,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, many models consider the number of memory transfers from slow memory to fast memory as a performance measure, and algorithms are designed to minimize these, since memory transfers take a significant amount of time."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:45:49.365063Z","inner_id":27,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1876,"annotations":[{"id":616,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"f_Oua_15Cx","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["Does not have any dependent clauses"]},"id":"WWBmsDR1qn","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:45:58.797335Z","updated_at":"2023-07-16T20:45:58.797335Z","draft_created_at":null,"lead_time":8.865,"prediction":{},"result_count":0,"unique_id":"67b928db-bcec-4279-ac94-4d200de560e7","last_action":null,"task":1876,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In contrast, highly-threaded, many-core machines are explicitly designed to have a large number of threads per core and a fast context switching mechanism."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:45:58.907420Z","inner_id":28,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1877,"annotations":[{"id":617,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"aW1oko68zH","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["2 independent clauses separated by a semicolon are classified as structured"]},"id":"DvuLFZjnog","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:46:14.160710Z","updated_at":"2023-07-16T20:46:14.160710Z","draft_created_at":"2023-07-16T20:46:11.895086Z","lead_time":14.69,"prediction":{},"result_count":0,"unique_id":"5ad42767-ee1a-426d-9742-24fa8dd3370f","last_action":null,"task":1877,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Highly-threaded many-cores are explicitly designed to hide memory latency; if a thread stalls on a memory operation, some other thread can be scheduled in its place."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:46:14.270543Z","inner_id":29,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1878,"annotations":[{"id":618,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"2rOvKwOE85","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["Not long enough"]},"id":"oZyXUqgUtQ","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:46:52.362495Z","updated_at":"2023-07-16T20:46:52.362495Z","draft_created_at":"2023-07-16T20:46:51.209271Z","lead_time":37.567,"prediction":{},"result_count":0,"unique_id":"b95e444e-e4c1-4976-a0e5-b4559a3c441c","last_action":null,"task":1878,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In principle, the number of memory transfers does not matter as long as there are enough threads to hide their latency."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:46:52.473468Z","inner_id":30,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1879,"annotations":[{"id":619,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Sprawling Ending"]]},"id":"t_uudjJWlX","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":[" (since we can ignore the effect of memory transfers) (which is exactly what PRAM model does.) has 2 clause tacked on at the end"]},"id":"1AN6DIg2Gk","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:48:22.910136Z","updated_at":"2023-07-16T20:48:22.910136Z","draft_created_at":"2023-07-16T20:47:11.905666Z","lead_time":89.931,"prediction":{},"result_count":0,"unique_id":"e4db9517-4a34-4290-92f3-4218f66ab784","last_action":null,"task":1879,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, if there are enough threads, we should, in principle, be able to use PRAM algorithms on such machines, since we can ignore the effect of memory transfers which is exactly what PRAM model does."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:48:23.020673Z","inner_id":31,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1880,"annotations":[{"id":620,"completed_by":2,"result":[{"value":{"taxonomy":[["Structured"]]},"id":"auFL3g01mH","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:49:06.506468Z","updated_at":"2023-07-16T20:49:06.506468Z","draft_created_at":"2023-07-16T20:48:40.721854Z","lead_time":42.808,"prediction":{},"result_count":0,"unique_id":"d3157a82-48de-41be-8f2b-377730a72636","last_action":null,"task":1880,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, the number of threads required to reach the point where one gets PRAM performance depends on both the algorithm and the hardware."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:49:06.618889Z","inner_id":32,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1881,"annotations":[{"id":621,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Long Intro Phrase"]]},"id":"Stz5Z4UhlU","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["Intro clause longer than 7 words"]},"id":"vBhTWKlo70","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:51:38.266674Z","updated_at":"2023-07-16T20:51:38.266674Z","draft_created_at":"2023-07-16T20:50:51.557389Z","lead_time":150.978,"prediction":{},"result_count":0,"unique_id":"bd428679-fc27-4511-b376-f55a75a860d3","last_action":null,"task":1881,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Since no highly-threaded, many-core machine allows an infinite number of threads, it is important to understand both (1) how many threads does a particular algorithm need to achieve PRAM performance, and (2) how does an algorithm perform when it has fewer threads than required to get PRAM performance?"},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:51:38.382398Z","inner_id":33,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1882,"annotations":[{"id":622,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Long Intro Phrase"]]},"id":"3HWqp_o5dh","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:52:30.397412Z","updated_at":"2023-07-16T20:52:30.397412Z","draft_created_at":"2023-07-16T20:52:29.347994Z","lead_time":51.451,"prediction":{},"result_count":0,"unique_id":"68734d49-d5fa-45e3-b2d8-d3412e83787b","last_action":null,"task":1882,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"To motivate this enterprise and to understand the importance of high thread counts on highly-threaded, many-core machines, let us consider a simple application that performs Bloom filter set membership tests on an input stream of biosequence data on GPUs [3]."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:52:30.508352Z","inner_id":34,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1883,"annotations":[{"id":623,"completed_by":2,"result":[{"value":{"taxonomy":[["NA"]]},"id":"1U-9Q-gEJ7","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:52:34.591980Z","updated_at":"2023-07-16T20:52:34.591980Z","draft_created_at":null,"lead_time":3.489,"prediction":{},"result_count":0,"unique_id":"ad659926-3a9e-4cc0-91b8-15d8130df568","last_action":null,"task":1883,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Fig. 1 shows the performance of this application, varying the number of threads per processor core, for two distinct GPUs."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:52:34.686654Z","inner_id":35,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1884,"annotations":[{"id":624,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Coordination"]]},"id":"oBxRTGgnCK","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"},{"value":{"text":["The sentences does not have good parallelism "]},"id":"He_L3FfZqh","from_name":"comment","to_name":"text","type":"textarea","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:57:26.534310Z","updated_at":"2023-07-16T20:57:26.534310Z","draft_created_at":"2023-07-16T20:55:44.840791Z","lead_time":290.953,"prediction":{},"result_count":0,"unique_id":"953197cb-43e2-4fec-9939-49c1543827ca","last_action":null,"task":1884,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"For both machines, the pattern is quite similar, at low thread counts, the performance increases (roughly linearly) with the number of threads, up until a transition region, after which the performance no longer increases with increasing thread count."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:57:26.643952Z","inner_id":36,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1885,"annotations":[{"id":625,"completed_by":2,"result":[{"value":{"taxonomy":[["Shapeless"],["Shapeless","Long Intro Phrase"]]},"id":"-y7E6S73UU","from_name":"taxonomy","to_name":"text","type":"taxonomy","origin":"manual"}],"was_cancelled":false,"ground_truth":false,"created_at":"2023-07-16T20:59:37.813298Z","updated_at":"2023-07-16T20:59:37.813298Z","draft_created_at":null,"lead_time":130.229,"prediction":{},"result_count":0,"unique_id":"b6960b2e-8c72-44b5-9fd9-ced3e2521612","last_action":null,"task":1885,"project":13,"updated_by":2,"parent_prediction":null,"parent_annotation":null,"last_created_by":null}],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"While the location of the transition region is different for distinct GPU models, this general pattern is found in many applications."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-16T20:59:37.923650Z","inner_id":37,"total_annotations":1,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":2,"comment_authors":[]},{"id":1886,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Once sufficient threads are present, the PRAM model adequately describes the performance of the application and increasing the number of threads no longer helps."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":38,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1887,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this work, we propose the Threaded Many-core Memory (TMM) model that captures the performance characteristics of these highly-threaded, many-core machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":39,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1888,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Note that while we motivate this model for highly-threaded many-core machines with synchronous computations, in principle, it can be used in any system which has fast context switching and enough threads to hide memory latency."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":40,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1889,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We do not try to model the Intel Xeon Phi, due to its limited use of threading for latency hiding."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":41,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1890,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In contrast, its approach to hide memory latency is primarily based on strided memory access patterns associated with vector computation."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":42,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1891,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"If the latency of transfers from slow memory to fast memory is small, or if the number of threads per processor is infinite, then this model generally provides the same analysis results as the PRAM analysis."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":43,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1892,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"(1) Ideally, we want to get the PRAM performance for algorithms using the fewest number of threads possible, since threads do have overhead."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":44,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1893,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"(2) It also captures the reality of when memory latency is large and the number of threads is large but finite."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":45,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1894,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In particular, it can distinguish between algorithms that have the same PRAM analysis, but one may be better at hiding latency than another with a bounded number of threads."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":46,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1895,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"This model is a high-level model meant to be generally applicable to a number of machines which allow a large number of threads with fast context switching."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":47,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1896,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, we are interested in the interplay between the farthest level, since the latencies are the largest at that level, and therefore have the biggest impact on the performance."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":48,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1897,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We analyze 4 classic algorithms for the problem of computing All Pairs Shortest Paths (APSP) on a weighted graph in the TMM model [43]."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":49,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1898,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We compare the analysis from this model with the PRAM analysis of these 4 algorithms to gain intuition about the usefulness of both our model and the PRAM model for analyzing performance of algorithms on highly-threaded, many-core machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":50,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1899,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Our results validate the intuition that this model can provide more information than the PRAM model for the large latency, finite thread case."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":51,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1900,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In particular, we compare these algorithms and find specific relationships between hardware parameters (latency, fast memory size, limits on number of threads) under which some algorithms are better than others even if they have the same PRAM cost."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":52,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1901,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Following the formal analysis, we assess the utility of the model by comparing empirically measured performance on an individual machine to that predicted by the model."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":53,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1902,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"For two of the APSP algorithms, we illustrate the impact of various individual parameters on performance, showing the effectiveness of the model at predicting measured performance."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":54,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1903,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Section 5 provides the lessons learned from this model; in particular, we see that algorithms that have the same PRAM performance have different performance in the TMM model since they are better at hiding memory latency with fewer threads."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":55,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1904,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Section 7 shows performance measurements for a pair of the APSP algorithms executing on a commercial GPU, illustrating correspondence between model predictions and empirical measurements."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":56,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1905,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We then review recent work on algorithms and performance analysis of GPUs which are the most common current instantiations of highly-threaded, many-core machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":57,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1906,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In an early work, Aggarwal et al. [25] present the Hierarchical Memory Model (HMM) and use it for a theoretical investigation of the inherent complexity of solving problems in RAM with a memory hierarchy of multiple levels."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":58,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1907,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"It differs from the RAM model by defining that access to location x takes logx time, but it does not consider the concept of block transfers, which collects data into blocks to utilize spatial locality of reference in algorithms."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":59,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1908,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The Block Transfer model (BT) [27] addresses this deficiency by defining that a block of consecutive locations can be copied from memory to memory, taking one unit of time per element after the initial access time."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":60,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1909,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Alpern et al. propose the Memory Hierarchy (MH) Framework [26] that reflects important practical considerations that are hidden by the RAM and HMM models: data are moved in fixed size blocks simultaneously at different levels in the hierarchy, and the memory capacity as well as bus bandwidth are limited at each level."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":61,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1910,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Later, an 'ideal-cache' model was introduced in [23,24] allowing analysis of cache-oblivious algorithms that use asymptotically optimal amounts of work and move data asymptotically optimally among multiple levels of cache without the necessity of tuning program variables according to hardware configuration parameters."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":62,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1911,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In the parallel case, although widely used, the PRAM [30] model is unrealistic because it assumes all processors work synchronously and that interprocessor communication is free."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":63,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1912,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Quite different to PRAM, the Bulk-Synchronous Parallel (BSP) model [34] attempts to bridge theory and practice by allowing processors to work asynchronously, and it models latency and limited bandwidth for distributed memory machines without shared memory."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":64,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1913,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Culler et al. [33] offer a new parallel machine model called LogP based on BSP, characterizing a parallel machine by four parameters: number of processors, communication bandwidth, delay, and overhead."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":65,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1914,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"It reflects the convergence towards systems formed by a collection of computers connected by a communication network via message passing."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":66,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1915,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Vitter et al. [35] present a two-level memory model and give a realistic treatment of parallel block transfers in parallel machines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":67,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1916,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Arge et al. [36] present the Parallel External Memory (PEM) model with P processors and a two-level memory hierarchy, consisting of the main memory as external memory shared by all processors and caches as internal memory exclusive to each of the P processors."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":68,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1917,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Blelloch et al. [37] present a multi-core-cache model capturing the fact that multi-core machines have both per-processor private caches and a large shared cache on-chip."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":69,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1918,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Blelloch et al. [38] also propose a parallel cache-oblivious (PCO) model to account for costs of a wide range of cache hierarchies."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":70,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1919,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Chowdhury et al. [39] present a hierarchical multi-level caching model (HM), consisting of a collection of cores sharing an arbitrarily large main memory through a hierarchy of caches of finite but increasing sizes that are successively shared by larger groups of cores."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":71,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1920,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"They in [42] consider three types of caching systems for CMPs: D-CMP with a private cache for each core, S-CMP with a single cache shared by all cores, and multi-core with private L1 caches and a shared L2 cache."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":72,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1921,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"All the models above do not accurately describe highly-threaded, many-core systems, due to their distinctive architectures, i.e. the explicit use of many threads for the purpose of hiding memory latency."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":73,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1922,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"While there has not been much work on abstract machine models for highly-threaded, many-core machines, there has been a lot of recent work on designing calibrated performance models for particular instantiations of these machines such as NVIDIA GPUs."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":74,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1923,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Liu et al. [19] describe a general performance model that predicts the performance of a biosequence database scanning application fairly precisely."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":75,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1924,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"It is helpful for applications with 2D-block representations while choosing an appropriate block size by estimating cache misses, but is not completely general."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":76,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1925,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Ryoo et al. [46] summarize five categories of optimization mechanisms, and use two metrics to prune the GPU performance optimization space by 98% via computing the utilization and efficiency of GPU applications."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":77,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1926,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"They propose a simple yet efficient solution combining several well-known parallel computation models: PRAM, BSP, QRQW, but they do not model global memory coalescing."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":78,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1927,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Using a different approach, Hong et al. [17] propose another analytical model to capture the cost of memory operations by counting the number of parallel memory requests in terms of memory-warp parallelism (MWP) and computation-warp parallelism (CWP)."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":79,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1928,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Meantime, Baghsorkhi et al. [16] measure performance factors in isolation and later combine them to model the overall performance via workflow graphs so that the interactive effects between different performance factors are modeled correctly."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":80,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1929,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The model can determine data access patterns, branch divergence, and control flow patterns only for a restricted class of kernels on traditional GPU architectures."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":81,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1930,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Zhang and Owens [15] present a quantitative performance model that characterizes an application's performance as being primarily bounded by one of three potential limits: instruction pipeline, shared memory accesses, and global memory accesses."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":82,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1931,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"More recently, Sim et al. [48] develop a performance analysis framework that consists of an analytical model and profiling tools."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":83,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1932,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Parakh et al. [50] present a model to estimate both computation time by precisely counting instructions and memory access time by a method to generate address traces."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":84,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1933,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The model should abstract away the details of particular implementations so as to be applicable to many instantiations of these machines, while being particular enough to model the performance of algorithms on these machines with reasonable accuracy."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":85,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1934,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this section, we will describe the important characteristics of these highly-threaded, many-core architectures and our model for analyzing algorithms for these architectures."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":86,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1935,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The most important high-level characteristic of highly-threaded, many-core architectures is that they provide a large number of hardware threads and use fast and low-overhead context-switching in order to hide the memory access latency from slow global memory."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":87,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1936,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Highly-threaded, many-core architectures typically consist of a number of core groups, each containing a number of processors (or cores), a fixed number of registers, and a fixed quantity of fast local on-chip memory shared within a core group."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":88,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1937,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Registers and local on-chip memory are the fastest to access, while accessing the global memory may potentially take 100s of cycles."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":89,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1938,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The TMM model models these machines as having a memory hierarchy with two levels of memory: slow global memory and fast local memory."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":90,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1939,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In addition, on most highly-threaded, many-core machines, data is transferred from slow to fast memory in chunks; instead of just transferring one word at a time, the hardware tries to transfer a large number of words during a memory transfer."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":91,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1940,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The chunk can either be a cache line from hardware managed caches, or an explicitly-managed combined read from multiple threads."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":92,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1941,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Since this characteristic of using high-bandwidth transfers in order to counter high latencies is common to most many-core machines (and even most multi-core machines), the TMM model captures the chunk size as one of its parameters."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":93,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1942,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"When a thread group executing on a core group stalls on a slow memory access, in theory, a context switch occurs and another thread group is scheduled on that core group."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":94,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1943,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The TMM model captures the important characteristics of a highly-threaded, many-core architecture by using six parameters shown in Table 1."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":95,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1944,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"L is the latency for accessing the slow memory (in our case, the global memory which is shared by all the core groups)."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":96,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1945,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"C is the maximum chunk size; the number of words that can be read from slow memory to fast memory in one memory transfer."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":97,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1946,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The parameter Z represents the size of fast local memory per core group and Q represents the number of cores per core group."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":98,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1947,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this case, a many-core machine looks very much like a multi-core machine with a large number of low-overhead hardware threads."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":99,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1948,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"This limit is enforced due to many different constraints, such as constraints on the number of registers each thread uses and an explicit constraint on the number of threads."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":100,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1949,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We assume that the programmer has written a correct synchronous program and taken care to balance the workload across the core groups."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":101,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1950,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"T1 represents the work of the algorithm, that is, the total number of operations that the program must perform (including fast memory accesses)."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":102,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1951,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"For instance, if the many-core machine has a hardware managed cache, and the program accesses data sequentially, then there is only one memory operation for C memory accesses; these will count as one when accounting for M."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":103,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1952,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The TMM model is a high-level abstract model, meant to be applicable to many instantiations of hardware platforms that feature a large number of threads with fast context switching and a hierarchical memory subsystem of at least two levels with a large memory latency gap in between."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":104,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1953,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"On each of these core groups, there are a number of CUDA cores that share a fixed number of registers and on-chip (fast) memory shared among the cores of the core group."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":105,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1954,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Transfers between slow global memory and fast local memory can occur in chunks of at most 32 words; these chunks can only be created if the memory accesses are within a specified range."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":106,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1955,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Accessing the off-chip global memory usually takes 20 to 40 times more clock cycles than accessing the on-chip shared memory\/L1 cache [51]."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":107,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1956,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Streaming multiprocessors serve the same role as a core group, while CUDA cores are equivalent to the cores defined in TMM."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":108,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1957,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Considering AMD\/ATI GPUs and taking Cypress, the codename for Radeon HD5800 series GPUs, as an example, the architecture is composed of 20 Single-Instruction-Multiple-Data (SIMD) computation engines."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":109,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1958,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Every TP is arranged as a five-way or four-way Very Long Instruction Word (VLIW) processor, and consists of 5 Stream Cores (SC)."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":110,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1959,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Based on the description from Alverson et al. [52] about the nature of the computations this processor was designed to run, it is a purpose-built appliance for real-time graph analytics featuring graph-optimized hardware that provides up to 512 terabytes of global shared memory, massively-multi-threaded graph processors (named Threadstorm) supporting 128 threads\/processor, and highly scalable I\/O."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":111,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1960,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"There can be up to 65,000 threads in a 512 processor system and over 1 million threads at the maximum system size of 8192 processors, so that the latencies are hidden by accommodating many remote memory references in flight."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":112,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1961,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The processor's instruction execution hardware essentially does a context switch every instruction cycle, finding the next thread that is ready to issue an instruction into the execution pipeline."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":113,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1962,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Threads do not share anything, as the Threadstorm processor has 128 hardware copies of the register set, program counter, stack pointer, etc., necessary to hold the current state of one software thread that is executing on the processor."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":114,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1963,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Conceptually, each of the Threadstorm processors is mapped to a core group in the TMM model but, different than the two GPU architectures, it has only one core on-chip, thus Q equals 1."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":115,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1964,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In order to analyze program performance in the TMM model, we must first calculate the program parameters for the particular program."},"meta":{},"created_at":"2023-07-10T18:51:54.637494Z","updated_at":"2023-07-10T18:51:54.637494Z","inner_id":116,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1965,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Total work due to memory accesses is ML, but since this work is hidden by using threads, the real effective work due to memory accesses is (ML)\/T Therefore, we have (1)TE=O(max(T1,MLT))."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":117,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1966,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Note that this expression assumes perfect scheduling (the threads are context swapped with no overhead, as soon as they are stalled) and perfect load balance between threads."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":118,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1967,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, if the first two terms in the min of Eq. (3) dominate, then a highly-threaded, many-core algorithm's performance is the same as the corresponding PRAM algorithm."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":119,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1968,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, based on the machine parameters, algorithms that have the same PRAM performance can have different real performance on highly-threaded, many-core machines."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":120,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1969,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this section, we demonstrate the usefulness of our model by using it to analyze 4 different algorithms for calculating all pairs shortest paths in graphs."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":121,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1970,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Our first algorithm is a dynamic programming algorithm [53] that uses repeated matrix multiplication to calculate all pairs shortest paths."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":122,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1971,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Al is a transitive matrix where Aijl represents the shortest path from vertex i to vertex j using at most l intermediate edges."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":123,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1972,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"A1 is the same as the adjacency matrix A and we want to calculate An-1 to calculate all pairs shortest paths."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":124,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1973,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Note that, the structure of this equation is the same as the structure of a matrix multiplication operation where the sum is replaced by a min operation and the multiplication is replaced by an addition operation."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":125,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1974,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Parallelizing this algorithm for the PRAM model simply involves parallelizing the matrix multiplication algorithm such that each element in the matrix is calculated in parallel."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":126,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1975,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"TMM algorithms are tailored to highly-threaded, many-core architectures generally by using fast on-chip memory to avoid accesses to slow off-chip global memory, coalescing to diminish the time required to access slow memory, and threading to hide the latency of accesses to slow memory."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":127,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1976,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Following traditional block-decomposition techniques, sub-blocks of the result matrix (whose size is denoted by B) are assigned to core groups for computation."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":128,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1977,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The threads in a core group read in the required input sub-blocks, perform the computation of Eq. (4) for their assigned sub-block, and write the sub-block out to global memory."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":129,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1978,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Also note that since we must fit a BB block in a local memory of size Z on one core group, we get B=(Z)."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":130,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1979,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We can now compare the PRAM and TMM analysis and note that the speedup is P as long as ZCT\/L1."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":131,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1980,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Johnson's algorithm [54] is an all pairs shortest paths algorithm that uses Dijkstra's single source algorithm as the subroutine and calls it n times, once from each source vertex."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":132,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1981,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The single source algorithm consists of n insert operations, m decrease-key operations and n delete-min operations from a min-priority queue."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":133,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1982,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The standard way of implementing Dijkstra's algorithm is to use a binary or a Fibonacci heap to store the array elements."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":134,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1983,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"A simple parallel implementation of Johnson's algorithm using Dijkstra's algorithm consists of doing each single-source shortest path calculation in parallel."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":135,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1984,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Since n may be arbitrarily large compared to Z\/QT (the share of local memory for each thread), these heaps cannot fit in local memory and must be allocated on the slow global memory."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":136,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1985,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Note that each time the thread does a heap operation, it must access global memory, since the heaps are stored in global memory."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":137,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1986,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In addition, binary heap accesses are not predictable and regular, so the heap accesses from different threads cannot be coalesced."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":138,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1987,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"This allows us to conclude that this algorithm achieves linear speedup only if Lmin(X,Z\/Q), since each thread needs only constant memory."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":139,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1988,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, in this algorithm, we simply store the current estimates of the shortest path of vertices in an array instead of a binary heap."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":140,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1989,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We can improve the span by doing delete-min in parallel, since one can find the smallest element in an array in parallel using O(n) work and O(lgn) time using a parallel prefix computation."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":141,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1990,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The TMM algorithm is similar to the PRAM algorithm, except that each core group is responsible for a single-source shortest path calculation."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":142,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1991,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, all the threads on a single core group (QT in number) cooperate to calculate a single shortest path computation."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":143,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1992,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Since we assume that n>Z, the entire array does not fit in local memory and must be read with each delete-min operation."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":144,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1993,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Each single source computation takes O(mn) work, making the total work of all pairs shortest paths O(mn2) and the total span O(mn)."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":145,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1994,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"For each single source calculation, we maintain three arrays, A,B and W, of size m, and one array D of size n."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":146,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1995,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"A[i] contains the starting vertex of the edge that ends at B[i] and W[i] contains the weight of that edge."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":147,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1996,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We can now calculate the time and speedup assuming threads can read all the arrays coalesced, M=O(mn2\/C+n3\/C)=O(mn2\/C) for connected graphs."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":148,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1997,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Subject to the limits on threads of Tmin(X,Z\/(QS)) and S=O(1) for constant local memory usage per thread, this requires Lmin(CX,CZ\/Q)."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":149,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1998,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"As our analysis of shortest paths algorithms indicates, the TMM model allows us to take the unique properties of highly-threaded, many-core architectures into consideration while analyzing the algorithms."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":150,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":1999,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, the model provides more nuance in the analysis of these algorithms for the highly-threaded, many-core machines than the PRAM model."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":151,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2000,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this section, we will compare the running times of the various algorithms and see what interesting things this analysis tells us."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":152,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2001,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Table 3 indicates the running times of the various algorithms in both the PRAM model and the TMM model, as well as the conditions under which TMM results are the same as the PRAM results."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":153,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2002,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, the cut-off value for L is different for different algorithms where the performance in the TMM model differs from the PRAM model is different for different algorithms."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":154,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2003,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Since machine parameters do not scale with problem size, in principle, machine parameters cannot change the asymptotic performance of algorithms in terms of problem size."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":155,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2004,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"That is, if the PRAM analysis indicates that some algorithm has a running time of O(n) and another one has the running time of O(nlgn), for large enough n, the first algorithm is always asymptotically better since eventually lgn will dominate whatever machine parameter advantage the second algorithm may have."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":156,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2005,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Second, we will also do a non-asymptotic comparison where we compare algorithms when the problem size is relatively small, but not very small."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":157,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2006,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this case, even algorithms that are asymptotically worse in the PRAM model can be better in the TMM model, for large latency L."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":158,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2007,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"If m=O(n2\/lgn) (i.e., a somewhat sparse graph), these two algorithms have the same PRAM performance, but if Z\/Q<LZC\/Q, then the array implementation is better."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":159,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2008,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"For L=ZC\/Q, the binary heap implementation has a running time of O(n3C\/P), while the array implementation has a running time of simply O(n3\/P)."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":160,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2009,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The previous section shows the asymptotic power of the model; the results there hold for large sizes of graphs asymptotically."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":161,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2010,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, the TMM model can also help decide on what algorithm to use based on the size of the graph."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":162,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2011,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In particular for certain sizes of graphs, algorithm A can be better than algorithm B even if it is asymptotically worse in the PRAM model."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":163,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2012,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"For dense graphs n2\/m<C, the dynamic programming algorithm should be preferred, while for sparse graphs, Johnson's algorithm with arrays is better."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":164,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2013,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"First, for a particular machine, given two algorithms which are asymptotically similar, we can pick the more appropriate algorithm for that particular machine given its machine parameters."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":165,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2014,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"For small problem sizes, the asymptotically worse algorithm may in fact be better because it interacts better with the machine."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":166,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2015,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In particular, some algorithms can take advantage of smaller problems better than others, since they can use fast local memory more effectively."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":167,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2016,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Note that this does not mean that the entire problem fits in local memory, since the number of edges can still be much larger than the number of vertices."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":168,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2017,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this scenario, the number of memory accesses by the first, second, and fourth algorithms is not affected at all."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":169,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2018,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In the dynamic programming algorithm, we consider the array of size n2 and being able to fit a row into local memory does not reduce the number of memory transfers."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":170,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2019,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Since the local memory Z is shared among QT threads, each thread cannot hold its entire vertex array in local memory."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":171,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2020,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"As an example, compare the two versions of Johnson's algorithm, the one that uses arrays and the one that uses heaps."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":172,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2021,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"But in the TMM model, for large L, the algorithm that uses heaps has the running time of O(Lmnlgn\/(TP))=O(Ln3\/(TPlgn)), while the algorithm that uses arrays has the running time of O(Ln3\/(TPlg2n))."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":173,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2022,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Note that asymptotic analysis is a little dubious when we are talking about small problem sizes; therefore, this analysis should be considered skeptically."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":174,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2023,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, the analysis is rigorous when we consider the circumstance that local memory size grows with problem size (i.e., Z is asymptotic)."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":175,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2024,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Moreover, this type of analysis can still provide enough insight that it might guide implementation decisions under the more realistic circumstance of bounded (but potentially large) Z."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":176,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2025,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Again, the running time of the first,second, and third algorithms do not change, since they cannot take advantage of this property."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":177,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2026,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, the Bellman-Ford algorithm can take advantage of this property and each thread across all core groups is responsible for relaxing a single edge."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":178,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2027,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Now a portion of the arrays A,B and W fit in each core group's local memory and they never have to be read again."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":179,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2028,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, in the TMM model, Johnson's has run time of O(Lmnlgn\/(TP))=O(Ln3\/(TP)), while Bellman-Ford with a run time of O(Ln3\/(CTP)) flips to be the better one."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":180,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2029,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this section, we conduct experiments to understand the extent of the applicability of our model in explaining the performance of algorithms on a real machine."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":181,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2030,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"It is not meant to be an exhaustive empirical study of the model's applicability for all instances of highly-threaded, many-core machines."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":182,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2031,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We implemented two all-pairs shortest paths algorithms: the dynamic programming using matrix multiplication and Johnson's algorithm using arrays, on an NVIDIA GPU."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":183,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2032,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":" Effect of the number of threads: the fact that the TMM model incorporates the number of threads per processor in the model is the primary differentiator between the PRAM and TMM models."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":184,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2033,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"After this point, the number of threads does not matter, and the TMM model behaves the same as the PRAM model."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":185,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2034,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this set of experiments, we will use both the dynamic programming and Johnson's algorithms to demonstrate this dependence on the number of threads."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":186,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2035,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":" Effect of fast local memory size: in some algorithms, including the dynamic programming via matrix multiplication, the size of the fast memory affects the performance of the algorithm in the TMM model."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":187,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2036,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":" Comparison of the dynamic programming algorithm and Johnson's algorithm with arrays: for Johnson's algorithm using arrays, the PRAM performance does not depend on the graph's density."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":188,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2037,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, the TMM model predicts that performance can depend on the graph's density, when the number of threads is insufficient for the performance to be equivalent to the PRAM model."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":189,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2038,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, even though Johnson's algorithm is always faster than the dynamic programming algorithm according to the PRAM model (since its work is n3 while the dynamic programming algorithm has work n3lgn), the TMM model predicts that when the number of threads is small, the dynamic programming algorithm may do better, especially for dense graphs."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":190,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2039,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"As a typical highly-threaded, many-core machine, it also features a 1.5 GB global memory and 16 kB\/48 kB of configurable on-chip shared memory per multiprocessor, which can be accessed with latency significantly lower than the global memory."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":191,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2040,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Runtimes are measured across various configurations of each problem, including graph size, thread count, shared memory size, and graph density."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":192,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2041,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In many cases, however, the trends we wish to see are more readily apparent when performance is shown in terms of speedup rather than execution time."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":193,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2042,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"This poses a problem, however, as it is arguably meaningless to attempt to realistically measure the single-core execution time of an application deployed on a modern GPU."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":194,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2043,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We address this issue using the following technique: all speedup plots compare the measured, empirical execution time on P cores to the theoretical, asymptotic execution time on 1 core using the PRAM model."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":195,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2044,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"As a result, the speedup axis does not represent a quantitatively meaningful scale, and the scale is labeled \"arbitrary\" on the graphs to reflect this fact; however, the shape of the curves are representative of the speedup achievable relative to a fixed serial execution time."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":196,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2045,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The TMM model indicates that when the number of threads is small, the performance of algorithms depends on the number of threads."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":197,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2046,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"With sufficient number of threads, the performance converges to the PRAM performance and only depends on the problem size and the number of processors."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":198,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2047,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"To better utilize fast local memory, the problem is decomposed into sub-blocks, and we must also pick a block size."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":199,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2048,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Since we only care about the effect of threads and not the effect of shared memory (to be considered in the next subsection), here we show the results with a block size of 64, as it allows us to generate the maximum number of threads."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":200,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2049,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We increase the number of threads until we reach either the hardware limit or the limit imposed by the algorithm."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":201,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2050,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"We see that the speedup increases approximately linearly with the number of threads per core (as predicted by Eq. (10)) and then flattens out."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":202,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2051,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"This indicates that for this experiment, 16 is an estimated threshold of threads\/core where the TMM model switches to the \"PRAM range\" and the number of threads no longer matters."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":203,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2052,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Note that the expression for this threshold does not depend on the graph size, as it is equal to L\/ZC."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":204,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2053,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Also note that the speedup (both in and out of the PRAM range) is not impacted by the size of the graph (again as predicted by Eq. (10))."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":205,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2054,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"First, we never see the flattening of performance with increasing thread counts that is seen with the dynamic programming algorithm."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":206,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2055,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Therefore, it appears that Johnson's algorithm requires more threads to reach the PRAM range where the performance no longer depends on the number of threads."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":207,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2056,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"This is also predicted by our model as the number of threads\/core required by the dynamic programming algorithm to reach PRAM range is TL\/ZC while the corresponding number of threads required by Johnson's is TL\/C, clearly a larger threshold."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":208,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2057,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Johnson's algorithm is not taking advantage of the fast local memory, and this factor influences the number of threads required to hide the latency to global memory."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":209,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2058,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"This is consistent with the fact that we are in the TMM range where the runtime is (mnL\/TP) and not in the PRAM range where the runtime only depends on the number of vertices."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":210,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2059,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The linear relationship predicted by the last term of Eq. (21) (for dense graphs) is illustrated clearly in the figure."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":211,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2060,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Among our shortest paths algorithms, only the dynamic programming algorithm makes use of the local memory and the running time depends on this fast memory size."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":212,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2061,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Then, varying thread counts has the same effect as previously illustrated in Fig. 3, increasing threads\/core increases performance until the PRAM range is reached."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":213,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2062,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"But as we can see from the figure, different block sizes have different performance for the same number of threads\/core."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":214,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2063,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In order to isolate the effect of block size from the effects of other parameters, we also plot this data in a pair of different formats in Figs. 7 and 8, in both cases limiting the number of threads\/core to below the PRAM range (i.e., the range where speedup is linear in threads\/core)."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":215,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2064,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"As the curve indicates, the delta speedup increases linearly with the number of threads\/core, consistent with the model prediction of (B1-B2)T."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":216,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2065,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The second curve shows the ratio of the performance of block size 64 to block size 32, indicating a flat line, since the thread term cancels out."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":217,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2066,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"It is interesting to compare the dynamic programming algorithm and Johnson's algorithm with arrays, since the PRAM and the TMM model differ in predicting the relative performance of these algorithms."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":218,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2067,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"However, from Section 5.2, for a small number of threads\/core working on a dense graph, the TMM model predicts that dynamic programming may be better."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":219,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2068,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Consequently, TMM predicts Johnson's algorithm is generally faster than dynamic programming for sparse graphs, but slower for relatively dense ones."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":220,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2069,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In addition, for the dense graph, the figure also shows the intersection between the runtime curves of the two algorithms."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":221,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2070,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"At that point (32 threads\/core), dynamic programming has already been in the PRAM range with stable performance since 16 threads\/core, while Johnson's has not."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":222,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2071,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"The peak performance of Johnson's being better than that of dynamic programming is consistent with what the PRAM model predicts."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":223,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2072,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this paper, we present a memory access model, called the Threaded Many-core Memory (TMM) model, that is well suited for modern highly-threaded, many-core systems that employ many threads and fast context switching to hide memory latency."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":224,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2073,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In particular, it requires the work and depth (like PRAM algorithms), but also requires the analysis of the number of memory accesses."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":225,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2074,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Using these three values, we can properly order algorithms from slow to fast for many different settings of machine parameters on highly-threaded, many-core machines."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":226,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2075,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In addition, for certain problem sizes which fit in local memory, algorithms which are faster on PRAM may be slower under the TMM model."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":227,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2076,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"Further, we implemented a pair of the algorithms and showed empirical performance is effectively predicted by the TMM model under a variety of circumstances."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":228,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2077,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"To our knowledge, this is the first attempt to formalize the analysis of algorithms for highly-threaded, many-core computers using a formal model and asymptotic analysis."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":229,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2078,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"While in this paper we assume that it is global memory vs. memory local to core groups, in principle, it can be any two levels of fast and slow memory."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":230,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]},{"id":2079,"annotations":[],"file_upload":"ed94b45e-S0167739X13001349_filtered.txt","drafts":[],"predictions":[],"data":{"text":"In this case, the algorithms should perform well under all settings of parameters, allowing us to apply the model at any two levels and get the same results."},"meta":{},"created_at":"2023-07-10T18:51:54.653002Z","updated_at":"2023-07-10T18:51:54.653002Z","inner_id":231,"total_annotations":0,"cancelled_annotations":0,"total_predictions":0,"comment_count":0,"unresolved_comment_count":0,"last_comment_updated_at":null,"project":13,"updated_by":null,"comment_authors":[]}]